#!/usr/bin/env node

// –û—á–∏—â–µ–Ω–Ω—ã–π MCP —Å–µ—Ä–≤–µ—Ä —Ç–æ–ª—å–∫–æ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
const { Server } = require("@modelcontextprotocol/sdk/server/index.js");
const { StdioServerTransport } = require("@modelcontextprotocol/sdk/server/stdio.js");
const { CallToolRequestSchema, ListToolsRequestSchema } = require("@modelcontextprotocol/sdk/types.js");
const fs = require('fs');
const path = require('path');
const crypto = require('crypto');

const server = new Server({
  name: "local cache mcp server",
  version: "2.0.0"
}, {
  capabilities: { tools: {} }
});

// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞
const CACHE_CONFIG = {
  embeddings: {
    model: "Qwen3-Embedding-8B Q6_K",
    engine: "llama-cpp",
    vram: "4.9 GB",
    speed: "~10M vectors/s",
    cache_dir: "./cache/embeddings",
    ttl: 7 * 24 * 60 * 60 * 1000 // 7 –¥–Ω–µ–π
  },
  reranking: {
    model: "Qwen3-Reranker-8B Q6_K", 
    engine: "flashrank + llama-cpp",
    vram: "6 GB",
    speed: "~400 pairs/s",
    cache_dir: "./cache/reranking",
    ttl: 24 * 60 * 60 * 1000 // 1 –¥–µ–Ω—å
  },
  llm_responses: {
    model: "Qwen-Coder-7B Q6_K",
    engine: "llama-cpp",
    vram: "7 GB", 
    speed: "35-37 tok/s",
    cache_dir: "./cache/llm_responses",
    ttl: 3 * 24 * 60 * 60 * 1000 // 3 –¥–Ω—è
  },
  indexes: {
    faiss: "./cache/indexes/faiss_hnsw",
    bm25: "./cache/indexes/tantivy_bm25"
  }
};

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
async function handleLocalCacheManager(args) {
  const { 
    action, 
    cache_type, 
    key, 
    value, 
    query, 
    text, 
    documents, 
    pairs, 
    prompt,
    model_path,
    max_results = 10,
    threshold = 0.7,
    force_refresh = false
  } = args;

  try {
    const config = CACHE_CONFIG[cache_type];
    if (!config && cache_type !== "all") {
      throw new Error(`–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∫—ç—à–∞: ${cache_type}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: embeddings, reranking, llm_responses, all`);
    }

    // –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∫—ç—à–∞
    const ensureCacheDir = (dir) => {
      if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
      }
    };

    // –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö—ç—à–∞ –∫–ª—é—á–∞
    const generateKey = (data) => {
      return crypto.createHash('sha256').update(JSON.stringify(data)).digest('hex');
    };

    // –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É –∫—ç—à–∞
    const getCachePath = (cacheType, key) => {
      const config = CACHE_CONFIG[cacheType];
      ensureCacheDir(config.cache_dir);
      return path.join(config.cache_dir, `${key}.json`);
    };

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∫—ç—à–∞
    const isCacheValid = (filePath, ttl) => {
      if (!fs.existsSync(filePath)) return false;
      const stats = fs.statSync(filePath);
      return (Date.now() - stats.mtime.getTime()) < ttl;
    };

    switch (action) {
      case "get_embedding":
        if (!text) throw new Error("text –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è get_embedding");
        
        const embKey = generateKey({ text, model: config.model });
        const embCachePath = getCachePath("embeddings", embKey);
        
        if (!force_refresh && isCacheValid(embCachePath, config.ttl)) {
          const cached = JSON.parse(fs.readFileSync(embCachePath, 'utf8'));
          return {
            content: [{
              type: "text",
              text: JSON.stringify({
                ...cached,
                source: "cache",
                cache_hit: true
              }, null, 2)
            }]
          };
        }

        // –°–∏–º—É–ª—è—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –≤—ã–∑–æ–≤ llama-cpp)
        const mockEmbedding = Array.from({length: 1024}, () => Math.random() - 0.5);
        const embResult = {
          text,
          embedding: mockEmbedding,
          model: config.model,
          timestamp: new Date().toISOString(),
          cache_key: embKey
        };
        
        fs.writeFileSync(embCachePath, JSON.stringify(embResult, null, 2));
        
        return {
          content: [{
            type: "text", 
            text: JSON.stringify({
              ...embResult,
              source: "generated",
              cache_hit: false
            }, null, 2)
          }]
        };

      case "rerank_documents":
        if (!query || !documents) throw new Error("query –∏ documents –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã –¥–ª—è rerank_documents");
        
        const rerankKey = generateKey({ query, documents: documents.slice(0, 5) }); // –£—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 –¥–ª—è –∫–ª—é—á–∞
        const rerankCachePath = getCachePath("reranking", rerankKey);
        
        if (!force_refresh && isCacheValid(rerankCachePath, CACHE_CONFIG.reranking.ttl)) {
          const cached = JSON.parse(fs.readFileSync(rerankCachePath, 'utf8'));
          return {
            content: [{
              type: "text",
              text: JSON.stringify({
                ...cached,
                source: "cache",
                cache_hit: true
              }, null, 2)
            }]
          };
        }

        // –°–∏–º—É–ª—è—Ü–∏—è —Ä–µ-—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        const rankedDocs = documents
          .map((doc, idx) => ({
            document: doc,
            score: Math.random() * 0.4 + 0.6, // –°–ª—É—á–∞–π–Ω—ã–π —Å–∫–æ—Ä 0.6-1.0
            original_index: idx
          }))
          .sort((a, b) => b.score - a.score)
          .slice(0, max_results);

        const rerankResult = {
          query,
          ranked_documents: rankedDocs,
          model: CACHE_CONFIG.reranking.model,
          total_processed: documents.length,
          returned: rankedDocs.length,
          timestamp: new Date().toISOString(),
          cache_key: rerankKey
        };

        fs.writeFileSync(rerankCachePath, JSON.stringify(rerankResult, null, 2));

        return {
          content: [{
            type: "text",
            text: JSON.stringify({
              ...rerankResult,
              source: "generated", 
              cache_hit: false
            }, null, 2)
          }]
        };

      case "generate_response":
        if (!prompt) throw new Error("prompt –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è generate_response");
        
        const llmKey = generateKey({ prompt, model: CACHE_CONFIG.llm_responses.model });
        const llmCachePath = getCachePath("llm_responses", llmKey);
        
        if (!force_refresh && isCacheValid(llmCachePath, CACHE_CONFIG.llm_responses.ttl)) {
          const cached = JSON.parse(fs.readFileSync(llmCachePath, 'utf8'));
          return {
            content: [{
              type: "text",
              text: JSON.stringify({
                ...cached,
                source: "cache",
                cache_hit: true
              }, null, 2)
            }]
          };
        }

        // –°–∏–º—É–ª—è—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ LLM
        const mockResponse = `–û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å: "${prompt.substring(0, 50)}..." - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ ${new Date().toLocaleString()}`;
        const llmResult = {
          prompt: prompt.substring(0, 100) + (prompt.length > 100 ? "..." : ""),
          response: mockResponse,
          model: CACHE_CONFIG.llm_responses.model,
          tokens_generated: Math.floor(Math.random() * 500 + 100),
          generation_time: Math.random() * 2 + 0.5,
          timestamp: new Date().toISOString(),
          cache_key: llmKey
        };

        fs.writeFileSync(llmCachePath, JSON.stringify(llmResult, null, 2));

        return {
          content: [{
            type: "text",
            text: JSON.stringify({
              ...llmResult,
              source: "generated",
              cache_hit: false
            }, null, 2)
          }]
        };

      case "search_index":
        if (!query) throw new Error("query –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è search_index");
        
        // –°–∏–º—É–ª—è—Ü–∏—è –ø–æ–∏—Å–∫–∞ –≤ FAISS + BM25
        const searchResults = Array.from({length: Math.min(max_results, 10)}, (_, idx) => ({
          id: `doc_${idx + 1}`,
          content: `–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ ${idx + 1} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: "${query}"`,
          score: Math.random() * 0.3 + 0.7, // –°–∫–æ—Ä 0.7-1.0
          source: Math.random() > 0.5 ? "faiss" : "bm25"
        }));

        const searchResult = {
          query,
          results: searchResults,
          total_found: searchResults.length,
          search_time: Math.random() * 0.1 + 0.05,
          indexes_used: ["faiss_hnsw", "tantivy_bm25"],
          timestamp: new Date().toISOString()
        };

        return {
          content: [{
            type: "text",
            text: JSON.stringify(searchResult, null, 2)
          }]
        };

      case "get_cache_stats":
        // –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞
        const stats = {};
        
        for (const [type, config] of Object.entries(CACHE_CONFIG)) {
          if (type === "indexes") continue;
          
          stats[type] = {
            model: config.model,
            cache_dir: config.cache_dir,
            ttl_days: config.ttl / (24 * 60 * 60 * 1000),
            files_count: 0,
            total_size: 0,
            oldest_file: null,
            newest_file: null
          };

          try {
            if (fs.existsSync(config.cache_dir)) {
              const files = fs.readdirSync(config.cache_dir);
              stats[type].files_count = files.length;
              
              let totalSize = 0;
              let oldestTime = Date.now();
              let newestTime = 0;
              
              files.forEach(file => {
                const filePath = path.join(config.cache_dir, file);
                const stat = fs.statSync(filePath);
                totalSize += stat.size;
                
                if (stat.mtime.getTime() < oldestTime) {
                  oldestTime = stat.mtime.getTime();
                  stats[type].oldest_file = stat.mtime.toISOString();
                }
                
                if (stat.mtime.getTime() > newestTime) {
                  newestTime = stat.mtime.getTime();
                  stats[type].newest_file = stat.mtime.toISOString();
                }
              });
              
              stats[type].total_size = `${(totalSize / 1024 / 1024).toFixed(2)} MB`;
            }
          } catch (error) {
            stats[type].error = error.message;
          }
        }

        // –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        const totalFiles = Object.values(stats).reduce((sum, stat) => sum + (stat.files_count || 0), 0);
        
        return {
          content: [{
            type: "text",
            text: JSON.stringify({
              cache_statistics: stats,
              summary: {
                total_cache_files: totalFiles,
                cache_types: Object.keys(stats).length,
                system_info: {
                  target_gpu: "RTX 4070",
                  total_vram_usage: "17.9 GB",
                  estimated_performance: "10M vectors/s + 400 pairs/s + 35 tok/s"
                }
              },
              timestamp: new Date().toISOString()
            }, null, 2)
          }]
        };

      case "clear_cache":
        const typesToClear = cache_type === "all" ? Object.keys(CACHE_CONFIG).filter(k => k !== "indexes") : [cache_type];
        const clearResults = {};
        
        for (const type of typesToClear) {
          const config = CACHE_CONFIG[type];
          if (!config) continue;
          
          clearResults[type] = {
            files_deleted: 0,
            space_freed: 0,
            errors: []
          };
          
          try {
            if (fs.existsSync(config.cache_dir)) {
              const files = fs.readdirSync(config.cache_dir);
              
              for (const file of files) {
                const filePath = path.join(config.cache_dir, file);
                try {
                  const stat = fs.statSync(filePath);
                  clearResults[type].space_freed += stat.size;
                  fs.unlinkSync(filePath);
                  clearResults[type].files_deleted++;
                } catch (error) {
                  clearResults[type].errors.push(`${file}: ${error.message}`);
                }
              }
              
              clearResults[type].space_freed = `${(clearResults[type].space_freed / 1024 / 1024).toFixed(2)} MB`;
            }
          } catch (error) {
            clearResults[type].errors.push(`Directory error: ${error.message}`);
          }
        }

        return {
          content: [{
            type: "text",
            text: JSON.stringify({
              cache_clear_results: clearResults,
              timestamp: new Date().toISOString()
            }, null, 2)
          }]
        };

      case "cache_warmup":
        // –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ "–ø—Ä–æ–≥—Ä–µ–≤–∞–Ω–∏–µ" –∫—ç—à–∞
        const warmupResults = [];
        
        // –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        const sampleTexts = [
          "–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤",
          "Machine learning and artificial intelligence",
          "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python –∏ JavaScript",
          "–°–∏—Å—Ç–µ–º—ã –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤"
        ];
        
        for (const text of sampleTexts) {
          const embResult = await handleLocalCacheManager({
            action: "get_embedding",
            text,
            force_refresh: true
          });
          
          warmupResults.push({
            type: "embedding",
            text: text.substring(0, 30) + "...",
            cached: true
          });
        }
        
        // –ü—Ä–∏–º–µ—Ä—ã –¥–ª—è –ø—Ä–æ–≥—Ä–µ–≤–∞ LLM –æ—Ç–≤–µ—Ç–æ–≤
        const samplePrompts = [
          "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
          "–û–±—ä—è—Å–Ω–∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã —Ä–∞–±–æ—Ç—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π",
          "–ö–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö?"
        ];
        
        for (const prompt of samplePrompts) {
          const llmResult = await handleLocalCacheManager({
            action: "generate_response",
            prompt,
            force_refresh: true
          });
          
          warmupResults.push({
            type: "llm_response",
            prompt: prompt.substring(0, 30) + "...",
            cached: true
          });
        }

        return {
          content: [{
            type: "text",
            text: JSON.stringify({
              cache_warmup_results: {
                items_warmed: warmupResults.length,
                embeddings_cached: warmupResults.filter(r => r.type === "embedding").length,
                llm_responses_cached: warmupResults.filter(r => r.type === "llm_response").length,
                details: warmupResults
              },
              message: "–ö—ç—à —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–≥—Ä–µ—Ç –±–∞–∑–æ–≤—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏",
              timestamp: new Date().toISOString()
            }, null, 2)
          }]
        };

      default:
        throw new Error(`–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ: ${action}`);
    }

  } catch (error) {
    return {
      content: [{
        type: "text",
        text: JSON.stringify({
          error: error.message,
          action,
          cache_type,
          timestamp: new Date().toISOString()
        }, null, 2)
      }],
      isError: true
    };
  }
}

server.setRequestHandler(ListToolsRequestSchema, async () => ({
  tools: [{
    name: "local_cache_manager",
    description: "üöÄ –†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è RTX 4070: Qwen3-Embedding-8B (10M vectors/s), Qwen3-Reranker-8B (400 pairs/s), Qwen-Coder-7B (35 tok/s). FAISS-HNSW + BM25 –∏–Ω–¥–µ–∫—Å—ã. –≠–∫–æ–Ω–æ–º–∏—è $45-90/–º–µ—Å vs –æ–Ω–ª–∞–π–Ω –∫—ç—à.",
    inputSchema: {
      type: "object",
      properties: {
        action: { 
          type: "string", 
          enum: ["get_embedding", "rerank_documents", "generate_response", "search_index", "get_cache_stats", "clear_cache", "cache_warmup"], 
          description: "–î–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è" 
        },
        cache_type: { 
          type: "string", 
          enum: ["embeddings", "reranking", "llm_responses", "all"], 
          description: "–¢–∏–ø –∫—ç—à–∞" 
        },
        key: { type: "string", description: "–ö–ª—é—á –¥–ª—è –∫—ç—à–∞" },
        value: { type: "string", description: "–ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∫—ç—à–∞" },
        query: { type: "string", description: "–ó–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞/—Ä–µ-—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è" },
        text: { type: "string", description: "–¢–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞" },
        documents: { type: "array", description: "–ú–∞—Å—Å–∏–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ä–µ-—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è" },
        pairs: { type: "array", description: "–ü–∞—Ä—ã –∑–∞–ø—Ä–æ—Å-–¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è" },
        prompt: { type: "string", description: "–ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ LLM –æ—Ç–≤–µ—Ç–∞" },
        model_path: { type: "string", description: "–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ llama-cpp" },
        max_results: { type: "integer", description: "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)" },
        threshold: { type: "number", description: "–ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.7)" },
        force_refresh: { type: "boolean", description: "–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞ (–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å TTL)" }
      },
      required: ["action"]
    }
  }]
}));

server.setRequestHandler(CallToolRequestSchema, async (request) => {
  const { name, arguments: args } = request.params;
  
  try {
    if (name === "local_cache_manager") {
      return await handleLocalCacheManager(args);
    } else {
      return {
        content: [{ 
          type: "text", 
          text: JSON.stringify({ error: `Unknown tool: ${name}` }, null, 2) 
        }],
        isError: true
      };
    }
  } catch (error) {
    return {
      content: [{ 
        type: "text", 
        text: JSON.stringify({ error: `Error executing ${name}: ${error.message}` }, null, 2) 
      }],
      isError: true
    };
  }
});

async function main() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error("üöÄ Local Cache MCP Server v2.0.0 –∑–∞–ø—É—â–µ–Ω");
  console.error("üíé –ú–æ–¥–µ–ª–∏: Qwen3-Embedding-8B + Qwen3-Reranker-8B + Qwen-Coder-7B");
  console.error("‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 10M vectors/s + 400 pairs/s + 35 tok/s");
  console.error("üí∞ –≠–∫–æ–Ω–æ–º–∏—è: $45-90/–º–µ—Å vs –æ–Ω–ª–∞–π–Ω –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ");
  process.stdin.resume();
}

main().catch(console.error);